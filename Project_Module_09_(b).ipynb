{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gimmi-07/FFML_Projects_and_Labs/blob/main/Project_Module_09_(b).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROJECT\n",
        "\n",
        "FMML Module 09, Project (b) <br>\n",
        " NAME: Grishma Yenchilwar ( grishma.yenchilwar.cse@ghrce.raisoni.net ) <br>\n",
        " Date: 23 Mar 2024 <br>"
      ],
      "metadata": {
        "id": "3v1m3PMGpEAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 9(b): Convolutional Neural Networks Project\n",
        "\n",
        "## Module coordinator: Kushagra Agarwal\n",
        "\n"
      ],
      "metadata": {
        "id": "LF8nIY5yEw3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://hub.packtpub.com/wp-content/uploads/2018/04/iStock-851960058-696x464.jpg\" width=850px/>"
      ],
      "metadata": {
        "id": "2EIAlTLKPQj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, you will understand how you can perform emotion recognition using CNNs in a step-by-step manner. To make your task easier, we provide you the starter code for the project. It is expected that you should try to understand the project statement properly and perform the tasks in sequence. We will be using Pytorch framework for the implementation. You need to fill in the missing code parts to achieve a particular task. At the end, you will have a basic implementation ready for an emotion detection application.\n",
        "\n",
        "Basic steps involved in Emotion Recognition:\n",
        "- Face detection\n",
        "- Building classifier\n",
        "- Classifying emotions\n",
        "\n",
        "We will use a popular FER2013 dataset for this project."
      ],
      "metadata": {
        "id": "jL7zt_6bPNXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Explore the dataset\n",
        "The dataset contains 48 x 48 grayscale facial images of faces.The faces have been automatically registered so that the face is more or less centred and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression into one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)."
      ],
      "metadata": {
        "id": "hpBbqZ39FF_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.researchgate.net/profile/Chaudhary-Aqdus/publication/349055345/figure/fig3/AS:987834383085568@1612529478973/FER-2013-sample-images-for-facial-emotion-recognition.jpg\" width=650px/>"
      ],
      "metadata": {
        "id": "c9UGeEuTPr4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "kXy7bFuIFPA_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh_RSwSCEnrZ"
      },
      "outputs": [],
      "source": [
        "# We have imported the necessary packages here. Feel free to import anything more you need!\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import dlib\n",
        "import cv2\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and load dataset"
      ],
      "metadata": {
        "id": "o9BUAlmDFeEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1YrNrok2Z1udWWIpejXIdLk7duUq87s0N\n",
        "!unzip fer2013.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaPP5dHSFWgM",
        "outputId": "f5e22e95-06bb-4f28-9b41-1f6cf95fdb5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1YrNrok2Z1udWWIpejXIdLk7duUq87s0N\n",
            "From (redirected): https://drive.google.com/uc?id=1YrNrok2Z1udWWIpejXIdLk7duUq87s0N&confirm=t&uuid=78881493-7aaa-4bc7-89ff-325832f685f0\n",
            "To: /content/fer2013.csv.zip\n",
            "100% 101M/101M [00:02<00:00, 38.5MB/s] \n",
            "Archive:  fer2013.csv.zip\n",
            "replace fer2013.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset csv using pandas package. It displays the data in tabular form\n",
        "emotion_data = pd.read_csv('./fer2013.csv')\n",
        "print(emotion_data)"
      ],
      "metadata": {
        "id": "9LOSUCeZFglQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class dictionary for dataset\n",
        "classes = {0:\"Angry\", 1:\"Disgust\", 2:\"Fear\", 3:\"Happy\", 4:\"Sad\", 5:\"Surprise\", 6:\"Neutral\"}"
      ],
      "metadata": {
        "id": "petzLP_HFjNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize a few images from dataset"
      ],
      "metadata": {
        "id": "nyWdEqz3FpCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12,4))\n",
        "for i in range(10):\n",
        "  ax = plt.subplot(2,5,i+1)\n",
        "  # This is how we access ith row in 'pixels' column in the dataset table\n",
        "  img = emotion_data.iloc[i]['pixels'].split(' ') # Converting into array of ints\n",
        "  img = np.array(img).astype(int)\n",
        "\n",
        "  # Labels for our dataset\n",
        "  label = int(emotion_data.iloc[i]['emotion'])\n",
        "  ax.imshow(img.reshape((48,48)), cmap='gray')\n",
        "  ax.set_title(classes[label])\n",
        "  ax.set_axis_off()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nnuUwMwaFoWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names, counts = np.unique(emotion_data['Usage'].to_numpy(), return_counts=True)\n",
        "print('Number of samples in {} = {}'.format(names[0], counts[0])) #testset\n",
        "print('Number of samples in {} = {}'.format(names[1], counts[1])) #valset\n",
        "print('Number of samples in {} = {}'.format(names[2], counts[2])) #trainset"
      ],
      "metadata": {
        "id": "jOYEnyhqFquh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribution of class labels"
      ],
      "metadata": {
        "id": "exip5hjXF9uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot bar chart showing number of samples per class in the train set\n",
        "temp_train = emotion_data.loc[emotion_data['Usage'] == 'Training']\n",
        "df_temp_train = temp_train.sort_values(by = \"emotion\", inplace = False)\n",
        "fig = plt.figure(figsize = (7, 5))\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_title(\"Count of each Emotion in Train Data\", fontsize = 20)\n",
        "sns.countplot(x = \"emotion\", data = df_temp_train)\n",
        "plt.grid()\n",
        "for i in ax.patches:\n",
        "    ax.text(x = i.get_x() + 0.2, y = i.get_height()+1.5, s = str(i.get_height()), fontsize = 20, color = \"grey\")\n",
        "plt.xlabel(\"Classes\"+ str(classes))\n",
        "plt.ylabel(\"Count\", fontsize = 15)\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.xticks(rotation = 40)\n",
        "plt.show()\n",
        "\n",
        "### Task: Similarly, write the code below to plot the charts for remaining two sets also."
      ],
      "metadata": {
        "id": "9fu3LIjCFzva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the imbalance in the data through above graphs."
      ],
      "metadata": {
        "id": "RgyJVkVeGJiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Face detection: Many applications involving facial images as input data require face detection in the pipeline at this step. Here, we localise the face in the given image removing the irrelevant parts, making the face centered and occupying most of the part in the image. As mentioned earlier, our dataset already has more or less centered faces, so we will skip this step for now but when using some other dataset or using your own images (eg. from webcam) as you will do later, you can do this step to get a proper cropped face from the image."
      ],
      "metadata": {
        "id": "tGzXGpFgHcED"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKqBdliUNhiS"
      },
      "source": [
        "## Task 2: Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QmcaX7yNsMf"
      },
      "source": [
        "### Creating train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eBsC7i2-NTI",
        "outputId": "75d84a0b-2e61-43cb-c17a-fb0b080a6d06"
      },
      "source": [
        "X_train, y_train = [], []\n",
        "X_val, y_val = [], []\n",
        "X_test, y_test = [], []\n",
        "\n",
        "for index, row in emotion_data.iterrows():\n",
        "  k = row['pixels'].split(\" \")\n",
        "\n",
        "  if row['Usage'] == 'Training':\n",
        "    X_train.append(np.array(k))\n",
        "    y_train.append(row['emotion'])\n",
        "\n",
        "  # Similarly write the conditions for test and val splits here\n",
        "  ###### YOUR CODE HERE  ######\n",
        "\n",
        "\n",
        "\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_val, y_val = np.array(X_val), np.array(y_val)\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "print('Training set shape: ', X_train.shape, y_train.shape)\n",
        "print('Validation set shape: ', X_val.shape, y_val.shape)\n",
        "print('Testing set shape: ', X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape:  (28709, 2304) (28709,)\n",
            "Validation set shape:  (0,) (0,)\n",
            "Testing set shape:  (0,) (0,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pvWe82a_KIO"
      },
      "source": [
        "# To get data between 0 and 1\n",
        "X_train = X_train.astype(float) / 255.\n",
        "X_test = X_test.astype(float) / 255.\n",
        "X_val = X_val.astype(float) / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_A4SIWRYvVd"
      },
      "source": [
        "We will define a dataset wrapper over Pytorch Dataset class which takes in the numpy arrays we created and returns a sample with required preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkU6ZNlIl_uw"
      },
      "source": [
        "class Fer2013Dataset(Dataset):\n",
        "  def __init__(self, x, y, transforms=None):\n",
        "    self.x = x.reshape((-1, 48, 48))\n",
        "    self.y = y\n",
        "    self.transforms= transforms\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img, y = self.x[index], self.y[index]\n",
        "\n",
        "    if self.transforms is not None:\n",
        "        img = self.transforms(img)\n",
        "    return img, y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfyIAW5tYZXf"
      },
      "source": [
        "batch_size=32\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Create tensor dataset from above tensors\n",
        "train_dataset = Fer2013Dataset(X_train, y_train, transforms=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "val_dataset = Fer2013Dataset(X_val, y_val, transforms=transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "test_dataset = Fer2013Dataset(X_test, y_test, transforms=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVeKhcxOaOi-"
      },
      "source": [
        "## Task 3: Building a CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-fjjr6UZ1sc"
      },
      "source": [
        "# Define your CNN architecture here\n",
        "# To start with, let's say you can create a model with 4 relu-activated convs,\n",
        "# each followed by a pooling layer. Then, you can add 2-3 fully connected layers\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        #### YOUR CODE HERE  ####\n",
        "\n",
        "    def forward(self,x):\n",
        "        #### YOUR CODE HERE  ####\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh2oKndcbVKa"
      },
      "source": [
        "# Device (CPU/GPU)\n",
        "device = 'cpu' #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the CNN\n",
        "model = Net().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training/Testing functions"
      ],
      "metadata": {
        "id": "JffKONlJKQXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, loss_func, optimizer, num_epochs):\n",
        "\n",
        "  # Training mode\n",
        "  model.train()\n",
        "\n",
        "  train_losses = []\n",
        "  train_acc = []\n",
        "\n",
        "  # Train the model\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "      # clear gradients for this training step\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass\n",
        "      output = model(images)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = loss_func(output, labels)\n",
        "\n",
        "      # Backpropagation, compute gradients\n",
        "      loss.backward()\n",
        "\n",
        "      # Apply gradients\n",
        "      optimizer.step()\n",
        "\n",
        "      # Running loss\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # indices of max probabilities\n",
        "      _, preds = torch.max(output, dim=1)\n",
        "\n",
        "      # Calculate number of correct predictions\n",
        "      correct = (preds.float() == labels).sum()\n",
        "      running_acc += correct\n",
        "\n",
        "      # Average loss and acc values\n",
        "      epoch_loss = running_loss / len(train_loader.dataset)\n",
        "      epoch_acc = running_acc / len(train_loader.dataset)\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_acc.append(epoch_acc)\n",
        "    print ('Epoch {}/{}, Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch + 1, num_epochs, epoch_loss, epoch_acc*100))\n",
        "\n",
        "  return train_losses, train_acc"
      ],
      "metadata": {
        "id": "S6BE_5aPF_eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, testloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # Deactivate autograd engine (don't compute grads since we're not training)\n",
        "  with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # Calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # The class with the highest value is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network: %d %%' % (\n",
        "      100 * correct / total))"
      ],
      "metadata": {
        "id": "w2BCd3JOJHnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcBGf4oZdRYD"
      },
      "source": [
        "## Task 4: Training & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skrXHHTlfDNj"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKRqaFn6dU3t"
      },
      "source": [
        "# specify loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer with learning rate\n",
        "optimizer = None   # Pick an optimizer you think is suitable\n",
        "\n",
        "history = train(model, train_loader, criterion, optimizer, num_epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can fine-tune your model looking at below plots\n",
        "fig = plt.figure(figsize=(10,4))\n",
        "ax = fig.add_subplot(1,2, 1)\n",
        "ax.plot(np.arange(1,len(history[0])+1),history[0])\n",
        "plt.xlabel('Loss')\n",
        "plt.ylabel('Epochs')\n",
        "\n",
        "ax = fig.add_subplot(1,2, 2)\n",
        "ax.plot(np.arange(1,len(history[1])+1),history[1])\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Epochs')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NG1wb_bFKvv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIc4E7dDd-RJ"
      },
      "source": [
        "### Evaluate your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofh6NYJe_AfQ"
      },
      "source": [
        "# Visualize top K predictions\n",
        "def visualize_prediction(image, model, k=3):\n",
        "  model.eval()\n",
        "\n",
        "  preds = model(image.unsqueeze(1).float())\n",
        "\n",
        "  topk = torch.topk(preds, k, dim=1)\n",
        "  topk = topk.indices.numpy()\n",
        "  print('Top {} Predictions'.format(k))\n",
        "  for i in range(3):\n",
        "    print('{}) {}'.format(i+1, classes[topk[0][i]]))\n",
        "\n",
        "  plt.imshow(image[0].numpy(), cmap='gray')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "0HexADTCBiFU",
        "outputId": "2177aff3-2ced-4f9a-995e-bb8b9d3a8eb1"
      },
      "source": [
        "image, label = test_dataset[1]\n",
        "visualize_prediction(image, cnn)\n",
        "print('\\nTrue label: ', classes[int(label)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1) Happy\n",
            "2) Disgust\n",
            "3) Angry\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "True label:  Happy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NN8ebRBeZVL"
      },
      "source": [
        "# Print accuracy on test data\n",
        "true_labels, predicted_labels = test_model(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# BONUS TASK\n",
        "\n",
        "### How can you improve the performance of your model given that the number of datapoints is fixed?\n",
        "\n",
        "##### Hint: A very simple fix (discussed in Lab 2) is to use a pretrained CNN model. The pretrained model could be trained on any dataset (eg Imagenet) and the first few layers of the same can be directly used for this task.\n",
        "\n",
        "### You are encouraged to try out different pretrained models like ResNet/VGG/AlexNet and see how the performance improves. Do all the models result in similar accuracy?"
      ],
      "metadata": {
        "id": "FwAjEp34QCsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the performance of a model given a fixed number of datapoints, using a pretrained Convolutional Neural Network (CNN) model is an effective strategy. Pretrained models, such as ResNet, VGG, and AlexNet, have already been trained on large datasets (e.g., ImageNet) and have learned useful feature representations. By leveraging these pretrained models, you can fine-tune them for your specific task, which often leads to better performance, especially when you have a limited amount of data.\n",
        "\n",
        "### Steps to Use Pretrained Models\n",
        "\n",
        "1. **Choose a Pretrained Model:**\n",
        "   Select a pretrained model like ResNet, VGG, or AlexNet. These models come with pre-trained weights from large-scale datasets like ImageNet.\n",
        "\n",
        "2. **Load the Pretrained Model:**\n",
        "   Load the chosen pretrained model and include the pre-trained weights. Most deep learning libraries (e.g., TensorFlow, PyTorch) offer utilities to load these models easily.\n",
        "\n",
        "3. **Freeze Initial Layers:**\n",
        "   Freeze the initial layers of the pretrained model to retain the learned features. Typically, you keep the initial layers frozen and fine-tune the later layers to adapt to your specific task.\n",
        "\n",
        "4. **Modify the Final Layers:**\n",
        "   Replace the final layers of the pretrained model with layers suitable for your specific task. For instance, if you are working on a classification task with a different number of classes, modify the output layer accordingly.\n",
        "\n",
        "5. **Fine-Tune the Model:**\n",
        "   Train the modified model on your dataset. Since the initial layers are already well-trained, the model can converge faster and potentially achieve better performance.\n",
        "\n",
        "### Comparing Different Pretrained Models\n",
        "\n",
        "#### ResNet\n",
        "- **Architecture:** Residual Networks (ResNet) use skip connections to allow gradients to flow through the network more effectively, which mitigates the vanishing gradient problem.\n",
        "- **Performance:** Known for its strong performance in various tasks due to its deep architecture and effective training.\n",
        "\n",
        "#### VGG\n",
        "- **Architecture:** VGG networks are characterized by their simplicity and use of small convolutional filters (3x3). They have a deep but straightforward architecture.\n",
        "- **Performance:** VGG models are effective but can be computationally expensive due to their depth and large number of parameters.\n",
        "\n",
        "#### AlexNet\n",
        "- **Architecture:** AlexNet was one of the first deep networks to achieve significant performance gains in image classification tasks. It uses larger convolutional filters (e.g., 11x11, 5x5).\n",
        "- **Performance:** While less complex than ResNet and VGG, AlexNet set the stage for modern CNN architectures. It performs well but may not match the accuracy of more recent models.\n",
        "\n",
        "### Experiment and Evaluate\n",
        "\n",
        "To determine the best model for your specific task, you should:\n",
        "\n",
        "1. **Train and Evaluate Each Model:**\n",
        "   Train and fine-tune ResNet, VGG, and AlexNet on your dataset. Evaluate their performance using relevant metrics (e.g., accuracy, F1-score).\n",
        "\n",
        "2. **Compare Results:**\n",
        "   Compare the results to see which model achieves the highest accuracy and best performance on your fixed dataset.\n"
      ],
      "metadata": {
        "id": "iO4MvZDTqeYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "train_dataset = datasets.ImageFolder(root='path_to_train_data', transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Load a pretrained model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze initial layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the final layer for the new task\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, num_classes)  # num_classes is the number of output classes in your task\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "# Fine-tune the model\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "# Evaluate the model\n",
        "# (similar steps for validation/testing)\n"
      ],
      "metadata": {
        "id": "lvMFextdqsCS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}